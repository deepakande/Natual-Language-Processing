{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Wrangling and Text Pre-processing\n",
        "___"
      ],
      "metadata": {
        "id": "xKRAyldQonNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are usually multiple steps involved in cleaning and pre-processing textual data.The main goal of this step is to remove noise from the data. The noise in text data can be in different form, so in this section we will look into some common data cleaning task performed before any NLP task."
      ],
      "metadata": {
        "id": "xgHQvxS-o2M6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Business-use-cases-of-text-classification\" data-toc-modified-id=\"Business-use-cases-of-text-classification-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Business use cases of text classification</a></span></li><li><span><a href=\"#Importing-Libraries\" data-toc-modified-id=\"Importing-Libraries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Importing Libraries</a></span></li><li><span><a href=\"#Natural-Language-Processing-libraries\" data-toc-modified-id=\"Natural-Language-Processing-libraries-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Natural Language Processing libraries</a></span></li><li><span><a href=\"#Text-Preprocessing\" data-toc-modified-id=\"Text-Preprocessing-5\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Text Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lower-casing\" data-toc-modified-id=\"Lower-casing-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Lower casing</a></span></li><li><span><a href=\"#Punctuation-removal\" data-toc-modified-id=\"Punctuation-removal-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Punctuation removal</a></span></li><li><span><a href=\"#Identifying-and-Remove-Stop-Words\" data-toc-modified-id=\"Identifying-and-Remove-Stop-Words-5.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Identifying and Remove Stop Words</a></span></li><li><span><a href=\"#Tokenize-Text-in-Words\" data-toc-modified-id=\"Tokenize-Text-in-Words-5.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Tokenize Text in Words</a></span></li><li><span><a href=\"#NLTK-Word-Stemming\" data-toc-modified-id=\"NLTK-Word-Stemming-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>NLTK Word Stemming</a></span></li><li><span><a href=\"#Lemmatizing-Words-Using-WordNet\" data-toc-modified-id=\"Lemmatizing-Words-Using-WordNet-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Lemmatizing Words Using <a href=\"https://wordnet.princeton.edu/\" target=\"_blank\">WordNet</a></a></span></li><li><span><a href=\"#Stemming-and-Lemmatization-Difference\" data-toc-modified-id=\"Stemming-and-Lemmatization-Difference-5.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Stemming and Lemmatization Difference</a></span></li><li><span><a href=\"#Plotting-Frequencies-of-Words\" data-toc-modified-id=\"Plotting-Frequencies-of-Words-4.8\"><span class=\"toc-item-num\">4.8&nbsp;&nbsp;</span>Plotting Frequencies of Words</a></span></li><li><span>"
      ],
      "metadata": {
        "id": "2Kvlp2pzoWbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Natural Language Processing libraries\n",
        "\n",
        "- __[nltk](https://www.nltk.org/api/nltk.html)__ is the most popular Python package for Natural Language processing, it provides algorithms for __importing, cleaning, pre-processing text data__ in human language and then __apply computational linguistics algorithms like sentiment analysis__.\n",
        "- __[gensim](https://radimrehurek.com/gensim/)__ is a robust open-source vector space modeling and topic modeling toolkit implemented in Python. It uses NumPy, SciPy and optionally Cython for performance.\n",
        "- __[spaCy](https://spacy.io/)__ is an extremely optimized NLP library that is meant to be operated together with deep learning frameworks such as TensorFlow or PyTorch.\n",
        "- [Recommended to Use NLTK, library]"
      ],
      "metadata": {
        "id": "71LoS86vpD9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task:\n",
        "\n",
        "- Take any dataset of your choice, Dataset-Provided \"Trumptweets.csv\"; \n",
        "- For the dataset of your choice perform basic text cleaning process from - 4.1 - 4.8.\n"
      ],
      "metadata": {
        "id": "_kt4RMdsqyMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Dataset - Observations:\n",
        "\n"
      ],
      "metadata": {
        "id": "uRSEjFelqhmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/1.PBS-Materials/Information Retreival/Week-01/trumptweets.csv\", )\n"
      ],
      "metadata": {
        "id": "lwDgMlCXmxdo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "324df793-c96b-461a-adeb-42e6e3361e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f4abbf46f369>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"movie_reviews\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
          ]
        }
      ]
    }
  ]
}